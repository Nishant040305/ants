{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e7644fb",
   "metadata": {},
   "source": [
    "# HTTPS Proxy Interception Testing Prototype\n",
    "\n",
    "This notebook implements a basic prototype for testing the HTTPS proxy interception with LLM-based security analysis. We'll test:\n",
    "\n",
    "1. Basic mitmproxy setup and interception\n",
    "2. Simple LLM analyzer service\n",
    "3. Token detection and redaction\n",
    "4. Event logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "87c82630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import sqlite3\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "# Token pattern matching\n",
    "TOKEN_RE = re.compile(r'(sk-[A-Za-z0-9-_]{16,}|[A-Za-z0-9_]{24}\\.[A-Za-z0-9_]{6}\\.[A-Za-z0-9_-]{27}|[\\w-]{24}\\.[\\w-]{6}\\.[\\w-]{27})')\n",
    "APIKEY_RE = re.compile(r'(AKIA[0-9A-Z]{16})|([A-Za-z0-9]{32,})')\n",
    "\n",
    "# Configuration\n",
    "DB_PATH = \"events.db\"\n",
    "LLM_ANALYZER_URL = \"http://127.0.0.1:5001/analyze\"  # We'll implement this later\n",
    "ALERT_THRESHOLD = 6\n",
    "REDACT_THRESHOLD = 8\n",
    "BLOCK_THRESHOLD = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d3ca810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_db():\n",
    "    \"\"\"Initialize SQLite database for storing security events\"\"\"\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('''CREATE TABLE IF NOT EXISTS events\n",
    "                   (ts REAL, id TEXT, host TEXT, path TEXT, direction TEXT, \n",
    "                    severity INTEGER, tags TEXT, decision TEXT, reason TEXT)''')\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "# Initialize the database\n",
    "init_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fb501f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_event(event):\n",
    "    \"\"\"Store a security event in the database\"\"\"\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"INSERT INTO events VALUES (?,?,?,?,?,?,?,?,?)\",\n",
    "                (event[\"ts\"], event[\"id\"], event[\"host\"], event[\"path\"], \n",
    "                 event[\"direction\"], event[\"severity\"], json.dumps(event[\"tags\"]), \n",
    "                 event[\"decision\"], event[\"reason\"]))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def redact_text(text, tags):\n",
    "    \"\"\"Redact sensitive information from text based on tags\"\"\"\n",
    "    text = TOKEN_RE.sub(\"[REDACTED_TOKEN]\", text)\n",
    "    text = APIKEY_RE.sub(\"[REDACTED_KEY]\", text)\n",
    "    if \"email_in_message\" in tags or \"email_sensitive\" in tags:\n",
    "        text = re.sub(r'[\\w\\.-]+@[\\w\\.-]+', \"[REDACTED_EMAIL]\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "77cbb876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_payload(payload):\n",
    "    \"\"\"\n",
    "    Simple heuristic analyzer (to be replaced with LLM later)\n",
    "    Returns severity score, tags, and decision\n",
    "    \"\"\"\n",
    "    body = payload.get(\"body\", \"\")\n",
    "    headers = payload.get(\"headers\", {})\n",
    "    tags = []\n",
    "    severity = 0\n",
    "    \n",
    "    # Check for tokens in body\n",
    "    if TOKEN_RE.search(body):\n",
    "        tags.append(\"token_in_message\")\n",
    "        severity += 8\n",
    "    \n",
    "    # Check for tokens in headers\n",
    "    auth_header = headers.get(\"authorization\", \"\")\n",
    "    if TOKEN_RE.search(auth_header):\n",
    "        tags.append(\"token_in_header\")\n",
    "        severity += 6\n",
    "    \n",
    "    # Check for API keys\n",
    "    if APIKEY_RE.search(body):\n",
    "        tags.append(\"api_key_pattern\")\n",
    "        severity += 5\n",
    "    \n",
    "    # Check for emails\n",
    "    if re.search(r'[\\w\\.-]+@[\\w\\.-]+', body):\n",
    "        tags.append(\"email_in_message\")\n",
    "        severity += 2\n",
    "    \n",
    "    # Clamp severity\n",
    "    severity = min(max(severity, 0), 10)\n",
    "    \n",
    "    # Determine decision\n",
    "    if severity >= BLOCK_THRESHOLD:\n",
    "        decision = \"block\"\n",
    "    elif severity >= REDACT_THRESHOLD:\n",
    "        decision = \"redact\"\n",
    "    elif severity >= ALERT_THRESHOLD:\n",
    "        decision = \"alert\"\n",
    "    else:\n",
    "        decision = \"allow\"\n",
    "    \n",
    "    reason = f\"Found {len(tags)} potential issues. Severity: {severity}\"\n",
    "    \n",
    "    return {\n",
    "        \"severity\": severity,\n",
    "        \"tags\": tags,\n",
    "        \"decision\": decision,\n",
    "        \"reason\": reason,\n",
    "        \"explain\": f\"Analysis found {', '.join(tags)} with severity {severity}\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b09269c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fdcc6537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Load environment variables and configure Gemini\n",
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "async def analyze_with_llm(http_packet):\n",
    "    \"\"\"\n",
    "    Analyze HTTP packet content using Gemini LLM\n",
    "    \n",
    "    Args:\n",
    "        http_packet (HTTPPacket): The packet to analyze\n",
    "    Returns:\n",
    "        dict: Analysis results including severity and recommendations\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Construct a detailed prompt for the LLM\n",
    "        prompt = f\"\"\"Analyze this HTTP packet for security implications and data leakage.\n",
    "        \n",
    "HTTP Request Details:\n",
    "Method: {http_packet.method}\n",
    "URI: {http_packet.uri}\n",
    "Source IP: {http_packet.metadata.src_ip}\n",
    "Destination IP: {http_packet.metadata.dst_ip}\n",
    "Headers: {json.dumps(http_packet.headers, indent=2)}\n",
    "Body: {http_packet.body if http_packet.body else 'No body content'}\n",
    "\n",
    "Analyze for:\n",
    "1. Sensitive data exposure (API keys, tokens, credentials)\n",
    "2. Security vulnerabilities\n",
    "3. Suspicious patterns or behavior\n",
    "4. Data privacy concerns\n",
    "\n",
    "Return your analysis in this JSON format:\n",
    "{{\n",
    "    \"severity\": <number 0-10>,\n",
    "    \"risk_level\": <\"low\"|\"medium\"|\"high\"|\"critical\">,\n",
    "    \"findings\": [<list of specific security findings>],\n",
    "    \"recommendations\": [<list of recommendations>],\n",
    "    \"sensitive_data_detected\": <boolean>,\n",
    "    \"explanation\": <detailed explanation>\n",
    "}}\"\"\"\n",
    "\n",
    "        # Get LLM analysis\n",
    "        response = model.generate_content(\n",
    "            prompt,\n",
    "            generation_config={\n",
    "                \"temperature\": 0.3,\n",
    "                \"top_p\": 0.8,\n",
    "                \"top_k\": 40,\n",
    "                \"max_output_tokens\": 1024,\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Parse response\n",
    "        try:\n",
    "            analysis = json.loads(response.text)\n",
    "            return analysis\n",
    "        except json.JSONDecodeError:\n",
    "            return {\n",
    "                \"severity\": 5,\n",
    "                \"risk_level\": \"medium\",\n",
    "                \"findings\": [\"Error parsing LLM response\"],\n",
    "                \"recommendations\": [\"Manual review required\"],\n",
    "                \"sensitive_data_detected\": False,\n",
    "                \"explanation\": \"Failed to parse LLM analysis\"\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in LLM analysis: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5d08d0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start live packet capture and analysis\n",
    "async def start_live_capture(interface=\"any\", duration=None):\n",
    "    \"\"\"\n",
    "    Start live packet capture with LLM-powered analysis\n",
    "    \n",
    "    Args:\n",
    "        interface (str): Network interface to capture on\n",
    "        duration (int): Capture duration in seconds (None for continuous)\n",
    "    \"\"\"\n",
    "    analyzer = EnhancedPacketAnalyzer(interface=interface)\n",
    "    \n",
    "    print(f\"üöÄ Starting live packet capture on interface: {interface}\")\n",
    "    print(f\"‚è±Ô∏è  Duration: {'Continuous' if duration is None else f'{duration} seconds'}\")\n",
    "    print(\"\\nüìù Analysis Configuration:\")\n",
    "    print(\"- Capturing: HTTP traffic\")\n",
    "    print(\"- Analysis: Real-time LLM-powered inspection\")\n",
    "    print(\"- Detection: Sensitive data and security risks\")\n",
    "    print(\"- Logging: High-risk events to SQLite\")\n",
    "    print(\"\\n‚ö° Live Capture Feed:\")\n",
    "    \n",
    "    try:\n",
    "        await analyzer.start_capture(duration=duration)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\n‚õî Capture stopped by user\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error during capture: {str(e)}\")\n",
    "    finally:\n",
    "        print(\"\\nüìä Final Statistics:\")\n",
    "        analyzer.print_statistics()\n",
    "\n",
    "# To start capturing:\n",
    "# asyncio.run(start_live_capture(duration=60))  # Capture for 60 seconds\n",
    "# or\n",
    "# asyncio.run(start_live_capture())  # Capture continuously until Ctrl+C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52217ae9",
   "metadata": {},
   "source": [
    "# Live HTTP Packet Analysis\n",
    "\n",
    "This section implements real-time HTTP packet capture and analysis. The system will:\n",
    "1. Capture live HTTP traffic on the specified network interface\n",
    "2. Extract and analyze packet payloads\n",
    "3. Detect sensitive information in real-time\n",
    "4. Log suspicious activities to the database\n",
    "\n",
    "Important Notes:\n",
    "- Requires administrator/root privileges for packet capture\n",
    "- Wireshark/TShark must be installed\n",
    "- Use responsibly and only on networks you own/have permission to monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "57bf36af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "async def run_enhanced_capture(duration=60):\n",
    "    \"\"\"Run enhanced packet capture for specified duration\"\"\"\n",
    "    analyzer = EnhancedPacketAnalyzer()\n",
    "    \n",
    "    try:\n",
    "        # Start capture\n",
    "        print(f\"Starting enhanced packet capture for {duration} seconds...\")\n",
    "        await analyzer.start_capture(duration=duration)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during capture: {str(e)}\")\n",
    "    finally:\n",
    "        # Print statistics\n",
    "        analyzer.print_statistics()\n",
    "        \n",
    "        # Print detailed info for last 5 suspicious packets\n",
    "        suspicious_packets = [p for p in analyzer.packets \n",
    "                            if p.body and analyze_payload({\n",
    "                                \"body\": p.body,\n",
    "                                \"headers\": p.headers\n",
    "                            })[\"decision\"] != \"allow\"]\n",
    "        \n",
    "        if suspicious_packets:\n",
    "            print(\"\\nüîç Last Suspicious Packets Details:\")\n",
    "            for packet in suspicious_packets[-5:]:\n",
    "                print(\"\\nPacket Details:\")\n",
    "                pprint(packet.to_dict())\n",
    "                print(\"-\" * 50)\n",
    "\n",
    "# To run the capture:\n",
    "# asyncio.run(run_enhanced_capture())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d471ca54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedPacketAnalyzer:\n",
    "    def __init__(self, interface=\"any\"):\n",
    "        self.interface = interface\n",
    "        self.capture = None\n",
    "        self.packets = []\n",
    "        self.stats = {\n",
    "            \"total_packets\": 0,\n",
    "            \"http_packets\": 0,\n",
    "            \"get_requests\": 0,\n",
    "            \"post_requests\": 0,\n",
    "            \"high_risk_packets\": 0,\n",
    "            \"sensitive_data_detected\": 0\n",
    "        }\n",
    "        \n",
    "    async def start_capture(self, duration=None):\n",
    "        \"\"\"Start capturing packets with optional duration\"\"\"\n",
    "        # Create capture with custom display filter for HTTP\n",
    "        self.capture = pyshark.LiveCapture(\n",
    "            interface=self.interface,\n",
    "            display_filter='http'  # Focus on HTTP traffic\n",
    "        )\n",
    "        \n",
    "        print(f\"Starting packet capture on interface: {self.interface}\")\n",
    "        print(f\"Duration: {'‚àû' if duration is None else f'{duration}s'}\")\n",
    "        \n",
    "        try:\n",
    "            # Start packet processing\n",
    "            if duration:\n",
    "                self.capture.sniff(timeout=duration)\n",
    "            else:\n",
    "                self.capture.sniff_continuously()\n",
    "                \n",
    "            for packet in self.capture:\n",
    "                await self.process_packet(packet)\n",
    "                \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n‚õî Stopping packet capture...\")\n",
    "        finally:\n",
    "            if self.capture:\n",
    "                self.capture.close()\n",
    "                \n",
    "    async def process_packet(self, packet):\n",
    "        \"\"\"Process and analyze a single packet\"\"\"\n",
    "        try:\n",
    "            # Create HTTPPacket object\n",
    "            http_packet = HTTPPacket(packet)\n",
    "            self.packets.append(http_packet)\n",
    "            \n",
    "            # Update basic statistics\n",
    "            self.stats[\"total_packets\"] += 1\n",
    "            if http_packet.http:\n",
    "                self.stats[\"http_packets\"] += 1\n",
    "                if http_packet.method == \"GET\":\n",
    "                    self.stats[\"get_requests\"] += 1\n",
    "                elif http_packet.method == \"POST\":\n",
    "                    self.stats[\"post_requests\"] += 1\n",
    "            \n",
    "            # Perform LLM analysis\n",
    "            if http_packet.body or http_packet.headers:\n",
    "                llm_analysis = await analyze_with_llm(http_packet)\n",
    "                if llm_analysis:\n",
    "                    if llm_analysis[\"risk_level\"] in [\"high\", \"critical\"]:\n",
    "                        self.stats[\"high_risk_packets\"] += 1\n",
    "                    if llm_analysis[\"sensitive_data_detected\"]:\n",
    "                        self.stats[\"sensitive_data_detected\"] += 1\n",
    "                    await self.handle_analysis_results(http_packet, llm_analysis)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing packet: {str(e)}\")\n",
    "            \n",
    "    async def handle_analysis_results(self, packet: HTTPPacket, analysis: dict):\n",
    "        \"\"\"Handle analysis results and alert on significant findings\"\"\"\n",
    "        if analysis[\"risk_level\"] in [\"high\", \"critical\"]:\n",
    "            print(\"\\nüö® High Risk Packet Detected!\")\n",
    "            print(\"=\" * 60)\n",
    "            print(f\"Time: {packet.metadata.timestamp}\")\n",
    "            print(f\"Risk Level: {analysis['risk_level'].upper()}\")\n",
    "            print(f\"Severity Score: {analysis['severity']}/10\")\n",
    "            print(f\"\\nSource: {packet.metadata.src_ip}:{packet.metadata.src_port}\")\n",
    "            print(f\"Destination: {packet.metadata.dst_ip}:{packet.metadata.dst_port}\")\n",
    "            print(f\"Method: {packet.method}\")\n",
    "            print(f\"URI: {packet.uri}\")\n",
    "            print(\"\\nFindings:\")\n",
    "            for finding in analysis[\"findings\"]:\n",
    "                print(f\"‚Ä¢ {finding}\")\n",
    "            print(\"\\nRecommendations:\")\n",
    "            for rec in analysis[\"recommendations\"]:\n",
    "                print(f\"‚Ä¢ {rec}\")\n",
    "            print(\"=\" * 60)\n",
    "            \n",
    "            # Store event in database\n",
    "            event = {\n",
    "                \"ts\": packet.metadata.timestamp.timestamp(),\n",
    "                \"id\": str(uuid.uuid4()),\n",
    "                \"host\": packet.metadata.dst_ip,\n",
    "                \"path\": packet.uri,\n",
    "                \"direction\": \"request\" if packet.method else \"response\",\n",
    "                \"severity\": analysis[\"severity\"],\n",
    "                \"tags\": json.dumps(analysis[\"findings\"]),\n",
    "                \"decision\": analysis[\"risk_level\"],\n",
    "                \"reason\": analysis[\"explanation\"]\n",
    "            }\n",
    "            store_event(event)\n",
    "        \n",
    "    def print_statistics(self):\n",
    "        \"\"\"Print capture statistics\"\"\"\n",
    "        print(\"\\nüìä Capture Statistics\")\n",
    "        print(\"=\" * 40)\n",
    "        print(f\"Total Packets: {self.stats['total_packets']}\")\n",
    "        print(f\"HTTP Packets: {self.stats['http_packets']}\")\n",
    "        print(f\"GET Requests: {self.stats['get_requests']}\")\n",
    "        print(f\"POST Requests: {self.stats['post_requests']}\")\n",
    "        print(f\"High Risk Packets: {self.stats['high_risk_packets']}\")\n",
    "        print(f\"Sensitive Data Detected: {self.stats['sensitive_data_detected']}\")\n",
    "        print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b40f22f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "import pyshark\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "class PacketMetadata:\n",
    "    def __init__(self, packet):\n",
    "        self.timestamp = datetime.fromtimestamp(float(packet.sniff_timestamp))\n",
    "        self.src_ip = packet.ip.src if hasattr(packet, 'ip') else None\n",
    "        self.dst_ip = packet.ip.dst if hasattr(packet, 'ip') else None\n",
    "        self.protocol = packet.highest_layer\n",
    "        self.length = packet.length\n",
    "        self.src_port = packet[packet.transport_layer].srcport if hasattr(packet, 'transport_layer') else None\n",
    "        self.dst_port = packet[packet.transport_layer].dstport if hasattr(packet, 'transport_layer') else None\n",
    "        \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"timestamp\": self.timestamp.isoformat(),\n",
    "            \"src_ip\": self.src_ip,\n",
    "            \"dst_ip\": self.dst_ip,\n",
    "            \"protocol\": self.protocol,\n",
    "            \"length\": self.length,\n",
    "            \"src_port\": self.src_port,\n",
    "            \"dst_port\": self.dst_port\n",
    "        }\n",
    "\n",
    "class HTTPPacket:\n",
    "    def __init__(self, packet):\n",
    "        self.metadata = PacketMetadata(packet)\n",
    "        self.http = packet.http if hasattr(packet, 'http') else None\n",
    "        self.headers = {}\n",
    "        self.body = None\n",
    "        self.method = None\n",
    "        self.uri = None\n",
    "        self.response_code = None\n",
    "        self._parse_http_layer(packet)\n",
    "        \n",
    "    def _parse_http_layer(self, packet):\n",
    "        if not self.http:\n",
    "            return\n",
    "            \n",
    "        # Extract HTTP headers\n",
    "        for field in dir(packet.http):\n",
    "            if field.startswith(('request_', 'response_')):\n",
    "                header_name = field.replace('request_', '').replace('response_', '')\n",
    "                self.headers[header_name] = getattr(packet.http, field)\n",
    "        \n",
    "        # Extract method, URI, and response code\n",
    "        self.method = getattr(packet.http, \"request_method\", None)\n",
    "        self.uri = getattr(packet.http, \"request_uri\", None)\n",
    "        self.response_code = getattr(packet.http, \"response_code\", None)\n",
    "        \n",
    "        # Extract body if available\n",
    "        if hasattr(packet.http, 'file_data'):\n",
    "            self.body = packet.http.file_data\n",
    "            \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"metadata\": self.metadata.to_dict(),\n",
    "            \"http_info\": {\n",
    "                \"method\": self.method,\n",
    "                \"uri\": self.uri,\n",
    "                \"response_code\": self.response_code,\n",
    "                \"headers\": self.headers,\n",
    "                \"body\": self.body\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "33d3b77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test packet capture\n",
    "async def run_packet_capture(duration=30):\n",
    "    \"\"\"Run packet capture for specified duration (seconds)\"\"\"\n",
    "    analyzer = PacketAnalyzer()\n",
    "    \n",
    "    try:\n",
    "        # Create task for packet capture\n",
    "        capture_task = asyncio.create_task(analyzer.start_capture())\n",
    "        \n",
    "        # Run for specified duration\n",
    "        print(f\"Running packet capture for {duration} seconds...\")\n",
    "        await asyncio.sleep(duration)\n",
    "        \n",
    "        # Stop capture\n",
    "        if analyzer.capture:\n",
    "            analyzer.capture.close()\n",
    "        capture_task.cancel()\n",
    "        \n",
    "    except asyncio.CancelledError:\n",
    "        print(\"Packet capture stopped\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during packet capture: {str(e)}\")\n",
    "\n",
    "# Run the capture (uncomment to test)\n",
    "# asyncio.run(run_packet_capture())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6096e1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyshark\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "\n",
    "class PacketAnalyzer:\n",
    "    def __init__(self, interface=\"any\"):\n",
    "        self.interface = interface\n",
    "        self.capture = None\n",
    "        \n",
    "    async def start_capture(self):\n",
    "        \"\"\"Start capturing packets on specified interface\"\"\"\n",
    "        # Create capture with custom display filter\n",
    "        self.capture = pyshark.LiveCapture(\n",
    "            interface=self.interface,\n",
    "            display_filter='http or tls'  # Only capture HTTP/HTTPS traffic\n",
    "        )\n",
    "        \n",
    "        print(f\"Starting packet capture on interface: {self.interface}\")\n",
    "        print(\"Analyzing packets for sensitive information...\")\n",
    "        \n",
    "        try:\n",
    "            # Process each packet as it arrives\n",
    "            for packet in self.capture.sniff_continuously():\n",
    "                await self.analyze_packet(packet)\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nStopping packet capture...\")\n",
    "        finally:\n",
    "            if self.capture:\n",
    "                self.capture.close()\n",
    "    \n",
    "    async def analyze_packet(self, packet):\n",
    "        \"\"\"Analyze a single packet for sensitive information\"\"\"\n",
    "        try:\n",
    "            # Extract basic packet info\n",
    "            timestamp = datetime.fromtimestamp(float(packet.sniff_timestamp))\n",
    "            protocol = packet.transport_layer\n",
    "            src_addr = packet.ip.src\n",
    "            dst_addr = packet.ip.dst\n",
    "            \n",
    "            # Initialize payload data\n",
    "            payload = {\n",
    "                \"id\": str(uuid.uuid4()),\n",
    "                \"ts\": timestamp.timestamp(),\n",
    "                \"direction\": \"request\",  # or \"response\" based on port numbers\n",
    "                \"host\": dst_addr,\n",
    "                \"path\": \"\",\n",
    "                \"method\": \"\",\n",
    "                \"headers\": {},\n",
    "                \"body\": \"\",\n",
    "                \"source\": \"packet_capture\"\n",
    "            }\n",
    "            \n",
    "            # Extract HTTP-specific information if available\n",
    "            if hasattr(packet, 'http'):\n",
    "                payload[\"method\"] = getattr(packet.http, \"request_method\", \"\")\n",
    "                payload[\"path\"] = getattr(packet.http, \"request_uri\", \"\")\n",
    "                \n",
    "                # Extract headers\n",
    "                for field in dir(packet.http):\n",
    "                    if field.startswith(('request_', 'response_')):\n",
    "                        header_name = field.replace('request_', '').replace('response_', '')\n",
    "                        payload[\"headers\"][header_name] = getattr(packet.http, field)\n",
    "                \n",
    "                # Get HTTP payload if available\n",
    "                if hasattr(packet.http, 'file_data'):\n",
    "                    payload[\"body\"] = packet.http.file_data\n",
    "            \n",
    "            # Analyze the payload using our existing analyzer\n",
    "            result = analyze_payload(payload)\n",
    "            \n",
    "            # Log if suspicious\n",
    "            if result[\"decision\"] != \"allow\":\n",
    "                event = {\n",
    "                    \"ts\": payload[\"ts\"],\n",
    "                    \"id\": payload[\"id\"],\n",
    "                    \"host\": payload[\"host\"],\n",
    "                    \"path\": payload[\"path\"],\n",
    "                    \"direction\": payload[\"direction\"],\n",
    "                    \"severity\": result[\"severity\"],\n",
    "                    \"tags\": result[\"tags\"],\n",
    "                    \"decision\": result[\"decision\"],\n",
    "                    \"reason\": result[\"reason\"]\n",
    "                }\n",
    "                store_event(event)\n",
    "                print(f\"\\nAlert - {result['decision'].upper()}: {result['reason']}\")\n",
    "                print(f\"Host: {payload['host']}\")\n",
    "                print(f\"Path: {payload['path']}\")\n",
    "                print(f\"Severity: {result['severity']}\")\n",
    "                print(\"-\" * 80)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing packet: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3423d75e",
   "metadata": {},
   "source": [
    "# Network Packet Capture and Analysis\n",
    "\n",
    "Let's implement real-time packet capture and analysis using pyshark. This will allow us to:\n",
    "1. Capture HTTP/HTTPS packets\n",
    "2. Extract payload data\n",
    "3. Analyze packets for sensitive information\n",
    "4. Log suspicious packets to our database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e96a5f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Initializing HTTP Packet Analyzer...\n",
      "üì¶ Setting up database...\n",
      "üîë Loading configuration...\n",
      "ü§ñ Initializing LLM...\n",
      "\n",
      "‚úÖ Setup complete!\n",
      "üìù To start packet capture, run:\n",
      "   await start_live_capture()\n",
      "   or\n",
      "   asyncio.run(start_live_capture())\n",
      "\n",
      "‚ÑπÔ∏è  Make sure to run with administrator privileges!\n",
      "‚ÑπÔ∏è  Wireshark/TShark must be installed for packet capture to work\n"
     ]
    }
   ],
   "source": [
    "# Run the complete HTTP packet analyzer\n",
    "print(\"üîÑ Initializing HTTP Packet Analyzer...\")\n",
    "\n",
    "# Initialize database\n",
    "print(\"üì¶ Setting up database...\")\n",
    "init_db()\n",
    "\n",
    "# Configure environment\n",
    "print(\"üîë Loading configuration...\")\n",
    "load_dotenv()\n",
    "if not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "    print(\"‚ùå GOOGLE_API_KEY not found in .env file\")\n",
    "    print(\"Please create a .env file with: GOOGLE_API_KEY=your-api-key\")\n",
    "else:\n",
    "    # Configure Gemini\n",
    "    print(\"ü§ñ Initializing LLM...\")\n",
    "    genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "    \n",
    "    print(\"\\n‚úÖ Setup complete!\")\n",
    "    print(\"üìù To start packet capture, run:\")\n",
    "    print(\"   await start_live_capture()\")\n",
    "    print(\"   or\")\n",
    "    print(\"   asyncio.run(start_live_capture())\")\n",
    "    print(\"\\n‚ÑπÔ∏è  Make sure to run with administrator privileges!\")\n",
    "    print(\"‚ÑπÔ∏è  Wireshark/TShark must be installed for packet capture to work\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e003a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a09ae406",
   "metadata": {},
   "source": [
    "# Running with Administrator Privileges\n",
    "\n",
    "Since packet capture requires admin privileges, here are your options:\n",
    "\n",
    "## Option 1: Run Jupyter as Administrator\n",
    "1. **Close this notebook**\n",
    "2. **Right-click on Command Prompt** ‚Üí \"Run as administrator\" \n",
    "3. **Navigate to your project folder**: `cd C:\\Users\\Shiva\\Code\\Hack36`\n",
    "4. **Start Jupyter**: `jupyter notebook` or `jupyter lab`\n",
    "5. **Reopen this notebook**\n",
    "\n",
    "## Option 2: Use a Python Script Instead\n",
    "Save the code to a `.py` file and run it as admin:\n",
    "\n",
    "```bash\n",
    "# Right-click Command Prompt ‚Üí Run as administrator\n",
    "cd C:\\Users\\Shiva\\Code\\Hack36\n",
    "python packet_analyzer.py\n",
    "```\n",
    "\n",
    "## Option 3: Test Without Real Packets\n",
    "For development/testing, you can simulate packet analysis without actual capture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "268deb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully converted notebook to packet_analyzer.py\n",
      "\n",
      "üìù To run with admin privileges:\n",
      "1. Right-click Command Prompt ‚Üí 'Run as administrator'\n",
      "2. cd C:\\Users\\Shiva\\Code\\Hack36\n",
      "3. python packet_analyzer.py\n",
      "\n",
      "üí° The script will automatically run the packet capture!\n"
     ]
    }
   ],
   "source": [
    "# Convert notebook to Python script for admin execution\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "def convert_notebook_to_script():\n",
    "    \"\"\"Convert this notebook to a standalone Python script\"\"\"\n",
    "    try:\n",
    "        # Convert notebook to Python script\n",
    "        result = subprocess.run([\n",
    "            'jupyter', 'nbconvert', \n",
    "            '--to', 'python', \n",
    "            '--output', 'packet_analyzer',\n",
    "            'initial_testing.ipynb'\n",
    "        ], capture_output=True, text=True, cwd=os.getcwd())\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"‚úÖ Successfully converted notebook to packet_analyzer.py\")\n",
    "            print(\"\\nüìù To run with admin privileges:\")\n",
    "            print(\"1. Right-click Command Prompt ‚Üí 'Run as administrator'\")\n",
    "            print(\"2. cd C:\\\\Users\\\\Shiva\\\\Code\\\\Hack36\")\n",
    "            print(\"3. python packet_analyzer.py\")\n",
    "            print(\"\\nüí° The script will automatically run the packet capture!\")\n",
    "        else:\n",
    "            print(\"‚ùå Conversion failed:\")\n",
    "            print(result.stderr)\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ùå jupyter command not found. Make sure Jupyter is installed.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {str(e)}\")\n",
    "\n",
    "# Run the conversion\n",
    "convert_notebook_to_script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
